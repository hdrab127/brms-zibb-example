---
title: "Zero inflated Beta-binomial in brms"
author: "Hayden Rabel"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_document:
    toc: yes
---

```{r, SETTINGS-knitr, include=FALSE}
stopifnot(require(knitr))
options(width = 90)
opts_chunk$set(comment = NA,
               message = FALSE,
               warning = FALSE,
               eval = TRUE,
               dev = "png",
               dpi = 150,
               fig.asp = 0.8,
               fig.width = 8,
               out.width = "60%",
               fig.align = "center")
library(brms)
ggplot2::theme_set(theme_default())
```

## The Beta-binomial distribution

The Stan definition of the Beta-binomial probability mass function is:

If $N \in \mathbb{N}, \alpha \in \mathbb{R}^+,$ and $\beta \in \mathbb{R}^+$, then for $n \in 0,\dots,N$,

$$
\text{BetaBinomial}(n|N,\alpha,\beta) = \binom{n}{N}\frac{B(n + \alpha, N - n + \beta)}{B(\alpha, \beta)},
$$

where the beta function $B(u,v)$ is defined for $u \in \mathbb{R}^+$ and $v \in \mathbb{R}^+$ by

$$
B(u,v) = \frac{\Gamma(u)\Gamma(v)}{\Gamma(u + v)}.
$$

This distribution has a bunch of interesting properties on Wikipedia:

- $n = 1$ reduces it to the Bernoulli distribution.
- $\alpha = \beta = 1$ yields the discrete uniform distribution from $0$ to $n$.
- For large $\alpha, \beta$ it approximates the binomial distribution.
- For large $n, \beta$ it contains the negative binomial distribution in the limit.
- It is also a one-dimensional version of the Dirichlet-multinomial distribution.
- When $\alpha, \beta \in \mathbb{N}$ it is sometimes known as the negative hypergeometric distribution

## As a response distribution

The $\alpha$ and $\beta$ parameterisation above is tricky for `bmrs`, as both parameters control the shape. So, if we want to link predictors to the response, we would need to link to both $\alpha$ and $\beta$.

Thankfully, the Beta distribution can be re-parameterised in terms of it's mean $\mu \in (0, 1)$ and $\phi = \alpha + \beta > 0$ using

$\alpha = \mu \phi$ and $\beta = (1 - \mu)\phi$.

$\phi$ is interpreted like precision, sample size, or a measure of overdispersion:

- $\mu < 0.5 \implies \beta > \alpha$ and as $\phi$ increases, so does $\beta$ which increases right-skew, i.e., overdispersion.
- $\mu > 0.5 \implies \beta < \alpha$ and as $phi$ increases, so does $\alpha$ which increases left-skew.
- $\mu = 0.5 \implies \beta = \alpha$ and as the distribution is symmetric, with $\phi = 2$ creating a uniform shape, $\phi < 2$ concave, and $\phi > 2$ convex bell-shaped. 

We can rewrite the PMF above as

$$
\text{BetaBinomial}(n|N,\mu \phi, (1 - \mu)\phi) = \binom{n}{N}\frac{B(n + \mu \phi, N - n + (1 - \mu)\phi)}{B(\mu \phi, (1 - \mu)\phi)}.
$$

Now we can use a logit link function to obtain a linear predictor for $\mu$, the expected average success probability, as

$$
\ln\left(\frac{\mu}{1 -\mu}\right) = \eta = \beta_0 + \beta_1 x_1 + \dots ,
$$

where

$$
\mu = \frac{\exp(\eta)}{\exp(\eta) + 1}.
$$

## With zero inflation

It's likely that, in situations where the observed data has low average success probability, $\mu$, the standard Beta-binomial distribution should be able to account for excess zeros by estimating $\phi$ densities with higher modes. 

Though in situations where this is not enough, or it's suspected that there is a separate un-measured process creating these extra zeros, we can try a zero-inflated response distribution, specifically a mixture model where there is a probability $\theta$ of drawing a zero, and a $1 - \theta$ probability of drawing from the Beta-binomial distribution:

$$
p(n|N,\mu \phi, (1 - \mu)\phi,\theta) = \begin{cases}
\theta + (1 - \theta) \times \text{BetaBinomial}(0|N,\mu \phi, (1 - \mu)\phi) &\text{if}~n=0, \text{and}\\
(1 - \theta) \times \text{BetaBinomial}(n|N,\mu \phi, (1 - \mu)\phi) &\text{if}~n>0.
\end{cases}
$$

I.e., some of the zeros are contributed by the Beta-binomial distribution and some by a Bernoulli process, with mixing probability $\theta$.

## Tests

Is there a way to check predictors when using link identity? I.e., Beta and Beta-binom $\mu \in [0,1]$ but `brm` with `link = 'identity' allows any predictor outside of this range and MCMC diverges all over the place.

Note: I haven't tested truncated/censor models or within chain parallelisation for this yet.

## Example: Multilevel tadpoles

### Data

East African reed frog data from [Vonesh, J. R., & Bolker, B. M. (2005)](https://doi.org/10.1890/04-0535) with a few extra zeros added in.

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(brms)
data(reedfrogs, package = "rethinking")

# probability of zero survivals
set.seed(0)
zi <- 0.1

# update
reedfrogs <- 
  reedfrogs %>% 
  mutate(tank = 1:nrow(.),
         not_zero = runif(nrow(.)) > zi,
         across(c(surv, propsurv), ~ .x * not_zero)) %>% 
  as_tibble()
reedfrogs
```

### Model 1: plain binomial

$$
\begin{aligned}
surv_i &\sim \text{Binomial}(n_i,p_i)\\
\text{logit}(p_i) &= \alpha\\
\alpha &\sim \text{Normal}(0, 1.5).&
\end{aligned}
$$

```{r}
m1 <- 
  brm(data = reedfrogs, 
      family = binomial,
      formula = surv | trials(density) ~ 1,
      prior = prior(normal(0, 1.5), class = Intercept),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 0,
      file = '../brms-zibb-examples/m1.rds')
m1
```

### Model 2: Binomial with pooled varying intercepts

$$
\begin{aligned}
surv_i &\sim \text{Binomial}(n_i,p_i)\\
\text{logit}(p_i) &= \alpha_{\text{tank}[i]}\\
\alpha_j &\sim \text{Normal}(0, 1.5) &\text{for}~j=1,\dots,48.
\end{aligned}
$$

```{r}
m2 <- 
  brm(data = reedfrogs, 
      family = binomial,
      formula = surv | trials(density) ~ 0 + factor(tank),
      prior = prior(normal(0, 1.5), class = b),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 0,
      file = '../brms-zibb-examples/m2.rds')
m2
```

### Model 3: Beta-binomial

$$
\begin{aligned}
surv_i &\sim \text{BetaBinomial}(n_i,\bar{p_i},\phi)\\
\text{logit}(\bar{p_i}) &= \alpha\\
\alpha &\sim \text{Normal}(0, 1.5)\\
\phi &\sim \text{Gamma}(0.01, 0.01).
\end{aligned}
$$

```{r}
beta_binomial2 <- 
  custom_family("beta_binomial2", dpars = c("mu", "phi"),
                links = c("logit", "log"), lb = c(NA, 2),
                type = "int", vars = "vint1[n]")
stanvars <- 
  stanvar(scode = "
  real beta_binomial2_lpmf(int y, real mu, real phi, int T) {
    return beta_binomial_lpmf(y | T, mu * phi, (1 - mu) * phi);
  }
  int beta_binomial2_rng(real mu, real phi, int T) {
    return beta_binomial_rng(T, mu * phi, (1 - mu) * phi);
  }",
  block = "functions")

m3 <- 
  brm(data = reedfrogs, 
      family = beta_binomial2,
      formula = surv | vint(density) ~ 1,
      prior = c(prior(normal(0, 1.5), class = Intercept),
                prior(gamma(0.01, 0.01), class = phi)),
      stanvars = stanvars,
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 0,
      file = '../brms-zibb-examples/m3.rds')

expose_functions(m3, vectorize = TRUE)
log_lik_beta_binomial2 <- function(i, prep) {
  mu <- get_dpar(prep, "mu", i = i)
  phi <- get_dpar(prep, "phi", i = i)
  trials <- prep$data$vint1[i]
  y <- prep$data$Y[i]
  beta_binomial2_lpmf(y, mu, phi, trials)
}
posterior_predict_beta_binomial2 <- function(i, prep, ...) {
  mu <- get_dpar(prep, "mu", i = i)
  phi <- get_dpar(prep, "phi", i = i)
  trials <- prep$data$vint1[i]
  beta_binomial2_rng(mu, phi, trials)
}
posterior_epred_beta_binomial2 <- function(prep) {
  mu <- get_dpar(prep, "mu")
  trials <- prep$data$vint1
  trials <- matrix(trials, nrow = nrow(mu), ncol = ncol(mu), byrow = TRUE)
  mu * trials
}
m3
```


### Model 4: Zero-inflated beta-binomial

$$
\begin{aligned}
surv_i &\sim \text{ZiBetaBinomial}(n_i,\bar{p_i},\phi,\theta)\\
\text{logit}(\bar{p_i}) &= \alpha\\
\alpha &\sim \text{Normal}(0, 1.5)\\
\phi &\sim \text{Gamma}(0.01, 0.01)\\
\theta &\sim \text{Beta}(1, 1).
\end{aligned}
$$

```{r}
m4 <- 
  brm(data = reedfrogs, 
      family = zero_inflated_beta_binomial(),
      formula = surv | trials(density) ~ 1,
      prior = c(prior(normal(0, 1.5), class = Intercept),
                prior(gamma(0.01, 0.01), class = phi),
                prior(beta(1, 1), class = zi)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 0,
      file = '../brms-zibb-examples/m4.rds')
m4
```

### Compare

```{r fig.height=10}
ggpubr::ggarrange(pp_check(m1, ndraws = 20) +
                                      ggtitle(NULL, 'Binom'),
                                    pp_check(m2, ndraws = 20) +
                                      ggtitle(NULL, 'Binom pooled'),
                                    pp_check(m3, ndraws = 20) +
                                      ggtitle(NULL, 'Beta-binom'),
                                    pp_check(m4, ndraws = 20) +
                                      ggtitle(NULL, 'ZI Beta-binom'),
                                    ncol = 1,
                                    common.legend = TRUE) %>% 
  ggpubr::ggarrange(ggpubr::text_grob('Density'),
                    ncol = 1,
                    heights = c(19, 1)) %>% 
  ggpubr::ggarrange(ggpubr::text_grob('P(survival)', rot = 90),
                    .,
                    nrow = 1,
                    widths = c(1, 19))
suppressWarnings(loo(m1, m2, m3, m4)$diffs) %>% 
  knitr::kable()
```
